1. Parameters of the game: 
n = 6	b = 1	s = 3	t = 6	 
blocs=[(1, 1)]	 
	 
2. Parameters of each player: 
Player_O: 
d1 = 3	a1 = minimax	
heuritistic = slower_heuristic
Player_X: 
d2 = 6	a2 = minimax	
heuritistic = sophisticated_heuristic
	 

  ABCDEF
 +------
0|......
1|.B....
2|......
3|......
4|......
5|......

1. Evaluation time: 5.5894802s
Player O under AI control plays: x = 1, y = 3
ii. Heuristic evaluations: 3015
iii. Evaluations by depth: { depth=0:0 depth=1:32 depth=2:12 depth=3:2970 }
iv. Average evaluation depth: 2.9737976782752904

  ABCDEF
 +------
0|......
1|.B.O..
2|......
3|......
4|......
5|......

1. Evaluation time: 6.786947s
Player X under AI control plays: x = 2, y = 3
Player X loses because he exceeded the time limit
1. Parameters of the game: 
n = 6	b = 1	s = 3	t = 6	 
blocs=[(1, 1)]	 
	 
2. Parameters of each player: 
Player_O: 
d1 = 6	a1 = minimax	
heuritistic = slower_heuristic
Player_X: 
d2 = 3	a2 = minimax	
heuritistic = sophisticated_heuristic
	 

  ABCDEF
 +------
0|......
1|.B....
2|......
3|......
4|......
5|......

1. Evaluation time: 5.7996418s
Player O under AI control plays: x = 1, y = 3
ii. Heuristic evaluations: 3268
iii. Evaluations by depth: { depth=0:0 depth=1:34 depth=2:33 depth=3:32 depth=4:28 depth=5:20 depth=6:3120 }
iv. Average evaluation depth: 5.8531211750306

  ABCDEF
 +------
0|......
1|.B.O..
2|......
3|......
4|......
5|......

1. Evaluation time: 5.884239s
Player X under AI control plays: x = 2, y = 3
ii. Heuristic evaluations: 
904
iii. Evaluations by depth: {depth=0:0depth=1:33depth=2:6depth=3:864}
iv. Average evaluation depth: 2.9170353982300883

  ABCDEF
 +------
0|......
1|.B.O..
2|...X..
3|......
4|......
5|......

1. Evaluation time: 5.6863799s
Player O under AI control plays: x = 1, y = 4
ii. Heuristic evaluations: 3286
iii. Evaluations by depth: { depth=0:0 depth=1:32 depth=2:31 depth=3:30 depth=4:26 depth=5:2 depth=6:3164 }
iv. Average evaluation depth: 5.867924528301887

  ABCDEF
 +------
0|......
1|.B.OO.
2|...X..
3|......
4|......
5|......

1. Evaluation time: 5.77054s
Player X under AI control plays: x = 3, y = 2
ii. Heuristic evaluations: 
844
iii. Evaluations by depth: {depth=0:0depth=1:31depth=2:2depth=3:810}
iv. Average evaluation depth: 2.920616113744076

  ABCDEF
 +------
0|......
1|.B.OO.
2|...X..
3|..X...
4|......
5|......

1. Evaluation time: 5.7302001s
Player O under AI control plays: x = 1, y = 2
ii. Heuristic evaluations: 3308
iii. Evaluations by depth: { depth=0:0 depth=1:28 depth=2:28 depth=3:26 depth=4:21 depth=5:24 depth=6:3180 }
iv. Average evaluation depth: 5.878476420798065

  ABCDEF
 +------
0|......
1|.BOOO.
2|...X..
3|..X...
4|......
5|......

The winner is O!
FOR E1: 
Average evaluation time: 9.623666933333334
Number of states evaluated: 9862
average states per move at each depth: [0.0, 31.333333333333332, 30.666666666666668, 29.333333333333332, 25.0, 15.333333333333334, 3154.6666666666665]
total number of states: [0, 94, 92, 88, 75, 46, 9464]
Total number of moves: 3
FOR E2: 
Average evaluation time: 0.0
Number of states evaluated: 1748
average states per move at each depth: [0.0, 32.0, 4.0, 837.0]
total number of states: [0, 64, 8, 1674]
Total number of moves: 2
1. Parameters of the game: 
n = 6	b = 1	s = 3	t = 6	 
blocs=[(1, 1)]	 
	 
2. Parameters of each player: 
Player_O: 
d1 = 3	a1 = minimax	
heuritistic = slower_heuristic
Player_X: 
d2 = 6	a2 = minimax	
heuritistic = sophisticated_heuristic
	 

  ABCDEF
 +------
0|......
1|.B....
2|......
3|......
4|......
5|......

1. Evaluation time: 5.5888109s
Player O under AI control plays: x = 1, y = 3
ii. Heuristic evaluations: 3079
iii. Evaluations by depth: { depth=0:0 depth=1:32 depth=2:10 depth=3:3036 }
iv. Average evaluation depth: 2.9749918804806756

  ABCDEF
 +------
0|......
1|.B.O..
2|......
3|......
4|......
5|......

1. Evaluation time: 6.4428232s
Player X under AI control plays: x = 2, y = 3
Player X loses because he exceeded the time limit
1. Parameters of the game: 
n = 6	b = 1	s = 3	t = 6	 
blocs=[(1, 1)]	 
	 
2. Parameters of each player: 
Player_O: 
d1 = 6	a1 = minimax	
heuritistic = slower_heuristic
Player_X: 
d2 = 3	a2 = minimax	
heuritistic = sophisticated_heuristic
	 

  ABCDEF
 +------
0|......
1|.B....
2|......
3|......
4|......
5|......

1. Evaluation time: 5.7395871s
Player O under AI control plays: x = 1, y = 3
ii. Heuristic evaluations: 3587
iii. Evaluations by depth: { depth=0:0 depth=1:34 depth=2:33 depth=3:32 depth=4:28 depth=5:9 depth=6:3450 }
iv. Average evaluation depth: 5.8692500696961245

  ABCDEF
 +------
0|......
1|.B.O..
2|......
3|......
4|......
5|......

1. Evaluation time: 5.8566859s
Player X under AI control plays: x = 2, y = 3
ii. Heuristic evaluations: 
873
iii. Evaluations by depth: {depth=0:0depth=1:33depth=2:7depth=3:832}
iv. Average evaluation depth: 2.912943871706758

  ABCDEF
 +------
0|......
1|.B.O..
2|...X..
3|......
4|......
5|......

1. Evaluation time: 5.7197819s
Player O under AI control plays: x = 1, y = 4
ii. Heuristic evaluations: 3178
iii. Evaluations by depth: { depth=0:0 depth=1:32 depth=2:31 depth=3:30 depth=4:26 depth=5:6 depth=6:3052 }
iv. Average evaluation depth: 5.862177470106985

  ABCDEF
 +------
0|......
1|.B.OO.
2|...X..
3|......
4|......
5|......

1. Evaluation time: 5.868573s
Player X under AI control plays: x = 3, y = 2
ii. Heuristic evaluations: 
902
iii. Evaluations by depth: {depth=0:0depth=1:31depth=2:0depth=3:870}
iv. Average evaluation depth: 2.9279379157427936

  ABCDEF
 +------
0|......
1|.B.OO.
2|...X..
3|..X...
4|......
5|......

1. Evaluation time: 5.71663s
Player O under AI control plays: x = 1, y = 2
ii. Heuristic evaluations: 3452
iii. Evaluations by depth: { depth=0:0 depth=1:28 depth=2:28 depth=3:26 depth=4:21 depth=5:18 depth=6:3330 }
iv. Average evaluation depth: 5.885283893395133

  ABCDEF
 +------
0|......
1|.BOOO.
2|...X..
3|..X...
4|......
5|......

The winner is O!
FOR E1: 
Average evaluation time: 9.633752633333335
Number of states evaluated: 10217
average states per move at each depth: [0.0, 31.333333333333332, 30.666666666666668, 29.333333333333332, 25.0, 11.0, 3277.3333333333335]
total number of states: [0, 94, 92, 88, 75, 33, 9832]
Total number of moves: 3
FOR E2: 
Average evaluation time: 0.0
Number of states evaluated: 1775
average states per move at each depth: [0.0, 32.0, 3.5, 851.0]
total number of states: [0, 64, 7, 1702]
Total number of moves: 2
1. Parameters of the game: 
n = 6	b = 1	s = 3	t = 6	 
blocs=[(1, 1)]	 
	 
2. Parameters of each player: 
Player_O: 
d1 = 6	a1 = minimax	
heuritistic = slower_heuristic
Player_X: 
d2 = 3	a2 = minimax	
heuritistic = sophisticated_heuristic
	 

  ABCDEF
 +------
0|......
1|.B....
2|......
3|......
4|......
5|......

1. Evaluation time: 5.739243s
Player O under AI control plays: x = 1, y = 3
ii. Heuristic evaluations: 3558
iii. Evaluations by depth: { depth=0:0 depth=1:34 depth=2:33 depth=3:32 depth=4:28 depth=5:10 depth=6:3420 }
iv. Average evaluation depth: 5.867903316469927

  ABCDEF
 +------
0|......
1|.B.O..
2|......
3|......
4|......
5|......

1. Evaluation time: 5.891252s
Player X under AI control plays: x = 2, y = 3
ii. Heuristic evaluations: 
966
iii. Evaluations by depth: {depth=0:0depth=1:33depth=2:4depth=3:928}
iv. Average evaluation depth: 2.9244306418219463

  ABCDEF
 +------
0|......
1|.B.O..
2|...X..
3|......
4|......
5|......

1. Evaluation time: 5.7419269s
Player O under AI control plays: x = 1, y = 4
ii. Heuristic evaluations: 3557
iii. Evaluations by depth: { depth=0:0 depth=1:32 depth=2:31 depth=3:30 depth=4:25 depth=5:22 depth=6:3416 }
iv. Average evaluation depth: 5.872926623559179

  ABCDEF
 +------
0|......
1|.B.OO.
2|...X..
3|......
4|......
5|......

1. Evaluation time: 5.8627369s
Player X under AI control plays: x = 3, y = 2
ii. Heuristic evaluations: 
959
iii. Evaluations by depth: {depth=0:0depth=1:30depth=2:28depth=3:900}
iv. Average evaluation depth: 2.9051094890510947

  ABCDEF
 +------
0|......
1|.B.OO.
2|...X..
3|..X...
4|......
5|......

1. Evaluation time: 5.7004979s
Player O under AI control plays: x = 1, y = 2
ii. Heuristic evaluations: 3596
iii. Evaluations by depth: { depth=0:0 depth=1:28 depth=2:28 depth=3:26 depth=4:21 depth=5:12 depth=6:3480 }
iv. Average evaluation depth: 5.89154616240267

  ABCDEF
 +------
0|......
1|.BOOO.
2|...X..
3|..X...
4|......
5|......

The winner is O!
FOR E1: 
Average evaluation time: 9.645218900000001
Number of states evaluated: 10711
average states per move at each depth: [0.0, 31.333333333333332, 30.666666666666668, 29.333333333333332, 24.666666666666668, 14.666666666666666, 3438.6666666666665]
total number of states: [0, 94, 92, 88, 74, 44, 10316]
Total number of moves: 3
FOR E2: 
Average evaluation time: 0.0
Number of states evaluated: 1925
average states per move at each depth: [0.0, 31.5, 16.0, 914.0]
total number of states: [0, 63, 32, 1828]
Total number of moves: 2
1. Parameters of the game: 
n = 6	b = 1	s = 3	t = 6	 
blocs=[(1, 1)]	 
	 
2. Parameters of each player: 
Player_O: 
d1 = 3	a1 = minimax	
heuritistic = slower_heuristic
Player_X: 
d2 = 6	a2 = minimax	
heuritistic = sophisticated_heuristic
	 

  ABCDEF
 +------
0|......
1|.B....
2|......
3|......
4|......
5|......

1. Evaluation time: 5.5881522s
Player O under AI control plays: x = 1, y = 3
ii. Heuristic evaluations: 3303
iii. Evaluations by depth: { depth=0:0 depth=1:32 depth=2:3 depth=3:3267 }
iv. Average evaluation depth: 2.978807145019679

  ABCDEF
 +------
0|......
1|.B.O..
2|......
3|......
4|......
5|......

1. Evaluation time: 6.509439s
Player X under AI control plays: x = 2, y = 3
Player X loses because he exceeded the time limit
1. Parameters of the game: 
n = 6	b = 1	s = 3	t = 6	 
blocs=[(1, 1)]	 
	 
2. Parameters of each player: 
Player_O: 
d1 = 3	a1 = minimax	
heuritistic = slower_heuristic
Player_X: 
d2 = 6	a2 = minimax	
heuritistic = sophisticated_heuristic
	 
